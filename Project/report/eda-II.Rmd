# Exploratory data analysis

```{r data upload}

data<-read.csv2(here::here("data/GermanCredit.csv"), dec=".", header=T)

```

<!-- ### Collect additional data  -->
<!-- => not needed / not relevant for us, right?  -->

## Clean data

| Task | Raise the data quality to the level required by the selected analysis 
techniques. This may involve selection of clean subsets of the data, the 
insertion of suitable defaults or more ambitious techniques such as the 
estimation of missing data by modeling. | | Output | Describe what decisions and
actions were taken to address the data quality problems reported during the 
verify data quality task of the data understanding phase. Transformations of the
data for cleaning purposes and the possible impact on the analysis results 
should be considered. |


### Reconsider how to deal with observed type of noise 

We will consider how to correct the inconsistencies we have found, which are on three different variables, namely:

- EDUCATION: there was an error in the registration of the information and the -1 must be replaced by 1.
- PRESENT_RESIDENT: Again, there was an error in the registration of the information and the register was made in years instead of the category.
- AGE: Here it is clear that we have some outliers, we should limit the age to 75.

We have already decided how to correct them, hence we will move on to that direction. 

### Correct, remove or ignore noise 

```{r noise correction}

#EDUCATION
data %<>% 
  mutate(EDUCATION = replace(EDUCATION, EDUCATION == -1, 1))

#PRESENT_RESIDENT 
data %<>% 
  mutate(PRESENT_RESIDENT = PRESENT_RESIDENT - 1)

```

### Decide how to deal with special values and their meaning 

This is specifically for the case of AGE. As already previously said, we believe that the 125 age is an error, hence we will disgard it. 

```{r age correction}

#AGE
data %<>% 
  filter(AGE < 76)

```


## Construct data

| Task |This task includes constructive data preparation operations such as the 
production of derived attributes, entire new records or transformed values for 
existing attributes. | | Output | Derived attributes are new attributes that are
constructed from one or more existing attributes in the same record. Examples: 
area = length * width. </br> Describe the creation of completely new records. 
Example: create records for customers who made no purchase during the past year.
There was no reason to have such records in the raw data, but for modeling 
purposes it might make sense to explicitly represent the fact that certain 
customers made zero purchases.|


### Check available constuction mechanisms 

We could create the sex variable thanks to the MALE_DIV, MALE_SINGLE and MALE_MAR_WID variables. 

This variable will take value 1 if the person is male, and value 0 if it is female. 

```{r male creation}

data %<>% 
  mutate(SEX_MALE = ifelse((MALE_DIV | MALE_SINGLE | MALE_MAR_or_WID) == 1, 1, 0)) 

```

#### Exploration of new variable 

We will now explore a bit the new variable we have created. 

```{r EDA SEX_MALE}

#Respesentation of SEX_MALE per value
data %>% 
  ggplot(aes(SEX_MALE)) + 
  geom_bar(aes(fill = factor(SEX_MALE))) + theme(legend.position = "none")  + geom_label(stat = 'count', aes(label =..count..)) 

#Representation of output variable in terms of SEX_MALE
data %>% 
  ggplot(aes(RESPONSE)) + 
  geom_bar(aes(fill = factor(SEX_MALE)), position = "dodge")+ 
  labs(color = "", fill = "SEX_MALE", x = "RESPONSE", y = "count") 

```

We can see that we have more observation with a positive value for the SEX_MALE variable, meaning that there are more men than women in the dataset. 

We can see a difference on the positive value for the response having a male rather than a female, but this could also be due to the fact that the presence of male is higher with respect to women. 

We have 309 women vs. 691 men.

The correlation with the output variable is `r cor(data$SEX_MALE, data$RESPONSE)`.

### Collide variables 

We could try to merge variables into a new one, so that instead of having multiple dummy variables, we have a factor variables with multiple levels. 

Variables that could be merged:
- Purpose of credit: NEW_CAR, USED_CAR, FURNITURE, RADIO/TV, EDUCATION, RETRAINING
- Property: REAL_ESTATE, PROP_UNKN_NONE
- Residence: RENT, OWN_RES 


#### Purpose 
Let's start with the purpose of credit. 

This variable will take the following values:
1 = the purpose for the credit was a new car
2 = the purpose for the credit was a used car
3 = the purpose for the credit was funriture
4 = the purpose for the credit was a radio or a television 
5 = the purpose for the credit was to increase eductation 
6 = the purpose for the credit was a retraining 
0 = the purpose for the credit was something else 

```{r purpose creation}

data %<>% 
  mutate(PURPOSE = ifelse(NEW_CAR == 1, 1, ifelse(USED_CAR == 1, 2, ifelse(FURNITURE == 1, 3, ifelse(RADIO.TV == 1, 4, ifelse(EDUCATION == 1, 5, ifelse(RETRAINING == 1, 6, 0))))))) %>% 
  mutate(PURPOSE = as.factor(PURPOSE))

```

Let's have a look at the new variable, in terms of number of observation per level and its link to the response variable. 

```{r EDA PURPOSE} 

data %>% 
  ggplot(aes(PURPOSE)) + geom_bar(aes(reorder(PURPOSE, -table(PURPOSE)[PURPOSE]), fill = PURPOSE)) + scale_fill_discrete(name = "PURPOSE", labels = c("OTHER", "NEW_CAR", "USED_CAR", "FURNITURE", "RADIO/TV", "EDUCATION", "RETRAINING")) + geom_label(stat = 'count', aes(label =..count..)) 

data %>% 
  ggplot(aes(RESPONSE)) + 
  geom_bar(aes(fill = factor(PURPOSE)), position = "dodge") + labs(x = "RESPONSE", y = "count") +  scale_fill_discrete(name = "PURPOSE", labels = c("OTHER", "NEW_CAR", "USED_CAR", "FURNITURE", "RADIO/TV", "EDUCATION", "RETRAINING")) + theme_bw()

```

#### Property 

Now we will create the property variable. 

We will start by looking at if the two variables that we want to use (namely, REAL_ESTATE and PROP_UNKN_NONE) are connected and hence it makes sense to put them together. 

In order to do so, we will perform a chi-squared independence test. The Chi-square test examines whether rows and columns of a contingency table are statistically significantly associated.

Null hypothesis (H0): the row and the column variables of the contingency table are independent.
Alternative hypothesis (H1): row and column variables are dependent
For each cell of the table, we have to calculate the expected value under null hypothesis.

This calculated Chi-square statistic is compared to the critical value (obtained from statistical tables) with df=(r−1)(c−1)
degrees of freedom and p = 0.05.

r is the number of rows in the contingency table
c is the number of column in the contingency table

If the calculated Chi-square statistic is greater than the critical value, then we must conclude that the row and the column variables are not independent of each other. This implies that they are significantly associated.

(http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r)

```{r chi-square test property}

chisq.test(data$REAL_ESTATE, data$PROP_UNKN_NONE)

```

We can see that the two variables are statistically significantly associated, as the p-value is really low, almost equal to 0.

We can conclude that it makes sense to merge the two variables into one factor variable, which will take value 1 if the person has a real estate, value 2 if the person is not known to have a property and value 0 otherwise. 

```{r property creation}

data %<>% 
  mutate(PROPERTY = as.factor(ifelse(REAL_ESTATE == 1, 1, ifelse(PROP_UNKN_NONE == 1, 2, 0))))

```

Let's have a look at the new variable in terms of number of observations per level and if there is a difference of occurences given the output variables. 

```{r EDA PROPERTY}

data %>% 
ggplot(aes(PROPERTY)) + geom_bar(aes(fill = PROPERTY)) + scale_fill_discrete(name = "PROPERTY", labels = c("OTHER", "REAL_ESTATE", "PROP_UNKN_NONE")) + geom_label(stat = 'count', aes(label =..count..))  

data %>% 
  ggplot(aes(RESPONSE)) + geom_bar(aes(fill = PROPERTY), position = "dodge") + scale_fill_discrete(name = "PROPERTY", labels = c("OTHER", "REAL_ESTATE", "PROP_UNKN_NONE"))

```

We can clearly see that the majority of the observations does not have a clear value for the property, being equal to 0 (563 compared to the 282 of REAL_ESTATE and 154 of PROP_UNKN_NONE).

If we consider the response, we cannot really see a difference from the person having a real estate or not having a property and having a credit rejected, while if they have a real estate it is more probable that they will get the credit compared to those who have not. Indeed, the correlation of the variable with the output is `r cor(as.numeric(data$PROPERTY), data$RESPONSE)`. 


#### Residence 

Now let's look at the third variable we wish to know if it is needed to be created. 

Let's start once again by the chi-squared independence test. 

```{r chi-square residence}

chisq.test(data$RENT, data$OWN_RES)

```

Also here, we can conclude that the two variables are statistically significantly associated, as the p-value is really low.

Hence we will create the residence variable, which will take value 1 if the person is renting, value 2 if the person is owning their own residence and value 0 otherwise. 

```{r residence creation}

data %<>% 
  mutate(RESIDENCE = as.factor(ifelse(RENT == 1, 1, ifelse(OWN_RES == 1, 2, 0))))

```


And let's explore the new variable a little bit, in terms of number of observations per level and if there is a difference in the possibility to get a credit given this variable. 

```{r RESIDENCE EDA}

data %>% 
  ggplot(aes(RESIDENCE)) + geom_bar(aes(fill = RESIDENCE)) + scale_fill_discrete(name = "RESIDENCE", labels = c("OTHER", "RENT", "OWN_RES"))+ geom_label(stat = 'count', aes(label =..count..)) 

data %>% 
  ggplot(aes(RESPONSE)) + geom_bar(aes(fill = RESIDENCE), position = "dodge") + scale_fill_discrete(name = "RESIDENCE", labels = c("OTHER", "RENT", "OWN_RES"))

```

Here, we can see that the majority of the people in the sample do own their own residence (712 observations, compared to the 108 of other and 179 of renting). 

Comparing it to the response variable, we can see that owning the residence seems to have an impact on the possibility to get the credit, while renting seems not to have a major impact. Indeed, the correlation with the output variable is `r cor(as.numeric(data$RESIDENCE), data$RESPONSE)`. 

## Select data 

| Task | Decide on the data to be used for analysis. Criteria include relevance 
to the data mining goals, quality and technical constraints such as limits on 
data volume or data types. Note that data selection covers selection of 
attributes (columns) as well as selection of records (rows) in a table. | | 
Output | List the data to be included/excluded and the reasons for these 
decisions.|

### Perform significance and correlation tests to decide what to include 

```{r correlation, echo=FALSE, fig.asp=1.2, message=FALSE, warning=FALSE}

cor(data[2:30], data$RESPONSE) %>% as.data.frame() %>% arrange(V1)

```

We can see that, in general, the correlation between the output variable and the explanatory variable is not particularly high, having a maximum of 0.35 with CHECK_ACC and a minimum of -0.21 with DURATION. 

```{r significance}

lm <- lm(RESPONSE ~ ., data = data[2:32])
summary(lm)

```

Given the signifcance of the variable by running a simple linear regression model, we believe that the most important variables are CHK_ACCOUNT, DURATION, HISTORY, NEW_CAR, EDUCATION, AMOUNT, SAV_ACCOUNT, INSTALL_RATE, EMPLOYMENT, MALE_SINGLE, GUARANTOR, PROP_UNKN_NONE, OTHER_INSTALL, FOREIGN and  TELEPHONE, which are in line with the correlation we have found before. We could choose to use only these variables, but we prefer to keep then and to perform a variable selection in terms of the different models that we will use in the next chapter. 

## Integrate data

| Task | These are methods whereby information is combined from multiple tables 
or records to create new records or values. | | Output | Merging tables refers 
to joining together two or more tables that have different information about the
same objects. </br> Merged data also covers aggregations. Aggregation refers to 
operations where new values are computed by summarizing together information 
from multiple records and/or tables.|

Here we integrate the variables we created in the dataset and we discard the ones we used to create them, so that we avoid the problem of multicollinearity. 

### Selecting variables we created and discard others 

```{r selection}

data_sel <- data %>% 
  select(CHK_ACCT, DURATION, HISTORY, PURPOSE, AMOUNT, SAV_ACCT, EMPLOYMENT, INSTALL_RATE, SEX_MALE, MALE_DIV, MALE_SINGLE, MALE_MAR_or_WID, CO.APPLICANT, GUARANTOR, PRESENT_RESIDENT, PROPERTY, AGE, OTHER_INSTALL, RESIDENCE, NUM_CREDITS, JOB, RESPONSE)

```


## Format data

| Task | Formatting transformations refer to primarily syntactic modifications 
made to the data that do not change its meaning, but might be required by the 
modeling tool. | | Output | Some tools have requirements on the order of the 
attributes, such as the first field being a unique identifier for each record or
the last field being the outcome field the model is to predict. It might be 
important to change the order of the records in the dataset. Perhaps the 
modeling tool requires that the records be sorted according to the value of the 
outcome attribute.  Additionally, there are purely syntactic changes made to 
satisfy the requirements of the specific modeling tool.|

No need, as we discarded those that were needed to be renamed. 

