# Exploratory data analysis

## Clean data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| Raise the data quality to the level required by the selected analysis techniques. This may involve selection of clean subsets of the data, the insertion of suitable defaults or more ambitious techniques such as the estimation of missing data by modeling.| Describe what decisions and actions were taken to address the data quality problems reported during the  verify data quality task of the data understanding phase. Transformations of the data for cleaning purposes and the possible impact on the analysis results should be considered. |


### Reconsider how to deal with observed type of noise 

We will consider how to correct the inconsistencies we have found in the previous chapter, which are on four different variables, namely:

- EDUCATION: there was an error in the registration of the information and the -1 must be replaced by 1.
- GUARANTOR: there was an error in the registration of the information and the 2 must be replaced by 1.
- PRESENT_RESIDENT: Again, there was an error in the registration of the information and the register was made in years instead of the category.
- AGE: Here it is clear that we have some outliers, we should limit the age to 75.

We have already decided how to correct them, hence we will move on to that direction. 

### Correct, remove or ignore noise 

We will start by correcting the noises of `EDUCATION`and `PRESENT_RESIDENT`, by simply replacing the value -1 with value 1 for the former and by changing the numbers of the categories for the latter by dimishing each value by 1, this is going to give us the true value corresponding to the description given in the data description that you can find in the appendix. 

```{r noise correction}

#EDUCATION
data %<>% 
  mutate(EDUCATION = replace(EDUCATION, EDUCATION == -1, 1))

#EDUCATION
data %<>% 
  mutate(GUARANTOR = replace(GUARANTOR, GUARANTOR == 2, 1))

#PRESENT_RESIDENT 
data %<>% 
  mutate(PRESENT_RESIDENT = PRESENT_RESIDENT - 1)

```

### Decide how to deal with special values and their meaning 

This is specifically for the case of AGE. As already previously said, we believe that the 125 age is an error, hence we will discard it by selecting only the observation with value lower then 76 (as 75 is the second highest value).

```{r age correction}

#AGE
data %<>% 
  filter(AGE < 76)

```

## Construct data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| This task includes constructive data preparation operations such as the production of derived attributes, entire new records or transformed values for existing attributes.| Derived attributes are new attributes that are constructed from one or more existing attributes in the same record. Examples: <br /> area = length * width. Describe the creation of completely new records. <br /> Example: create records for customers who made no purchase during the past year. There was no reason to have such records in the raw data, but for modeling purposes it might make sense to explicitly represent the fact that certain customers made zero purchases.|

### Check available constuction mechanisms 

As we already mentioned in the previous chapter, we will be able to create 4 different variables: 
1. A binary variable decribing the sex of the person (male vs. female)
2. A categorical variable for the purpose of the credit 
3. A categorical variable describing the real estate situation of the person (i.e. if someone owns a residence)
4. A categorical variable describing the property situation of the person (i.e. it they own their residence, are renting or something else)

#### Sex variable

We will start by the variable describing the sex of the considered person: this variable will be created thanks to the MALE_DIV, MALE_SINGLE and MALE_MAR_WID variables, and it will be a binary variable taking value 1 if the person is male, and value 0 if it is female. 

More specifically, if either one of the variables used to construct the new has value 1, so will the `SEX_MALE` variable, otherwise it will have value 0. 

```{r male creation}

data %<>% 
  mutate(SEX_MALE = ifelse((MALE_DIV | MALE_SINGLE | MALE_MAR_or_WID) == 1, 1, 0)) %>% 
  mutate(SEX_MALE = as.factor(SEX_MALE))

```

We will now explore a bit the new variable we have created. 

```{r EDA SEX_MALE}

#Respesentation of SEX_MALE per value
data %>% 
  ggplot(aes(SEX_MALE)) + 
  geom_bar(aes(fill = factor(SEX_MALE))) + 
  theme(legend.position = "none")  + 
  geom_label(stat = 'count', aes(label =..count..)) 

#Representation of output variable in terms of SEX_MALE
data %>% 
  ggplot(aes(RESPONSE)) + 
  geom_bar(aes(fill = factor(SEX_MALE)), position = "dodge")+ 
  labs(color = "", fill = "SEX_MALE", x = "RESPONSE", y = "count") 

```

We can see that we have more observation with a positive value for the SEX_MALE variable (690 vs. 309), meaning that there are more men than women in the dataset. 

We can see a difference on the positive value for the response having a male rather than a female, but this could also be due to the fact that the presence of male is higher with respect to women. 

### Collide variables 

We will now move on to the other variables aforementioned, so that instead of having multiple dummy variables, we have a factor variables with multiple levels. 

#### Purpose 

Let's start with the purpose of credit. 

This variable will take the following values:
1 = the purpose for the credit was a new car
2 = the purpose for the credit was a used car
3 = the purpose for the credit was funriture
4 = the purpose for the credit was a radio or a television 
5 = the purpose for the credit was to increase eductation 
6 = the purpose for the credit was a retraining 
0 = the purpose for the credit was something else 

```{r purpose creation}

data %<>% 
  mutate(PURPOSE = ifelse(NEW_CAR == 1, 1, 
                          ifelse(USED_CAR == 1, 2, 
                                 ifelse(FURNITURE == 1, 3, 
                                        ifelse(RADIO.TV == 1, 4, 
                                               ifelse(EDUCATION == 1, 5, 
                                                      ifelse(RETRAINING == 1, 6, 0))))))) %>% 
  mutate(PURPOSE = as.factor(PURPOSE))

```

Let's have a look at the new variable, in terms of number of observation per level and its link to the response variable. 

```{r EDA PURPOSE} 

data %>% 
  ggplot(aes(PURPOSE)) + 
  geom_bar(aes(reorder(PURPOSE, -table(PURPOSE)[PURPOSE]), fill = PURPOSE)) +
  scale_fill_discrete(name = "PURPOSE", 
                      labels = c("OTHER", "NEW_CAR", "USED_CAR", "FURNITURE", 
                                 "RADIO/TV", "EDUCATION", "RETRAINING")) + 
  geom_label(stat = 'count', aes(label =..count..)) 

data %>% 
  ggplot(aes(RESPONSE)) + 
  geom_bar(aes(fill = factor(PURPOSE)), position = "dodge") + 
  labs(x = "RESPONSE", y = "count") +  
  scale_fill_discrete(name = "PURPOSE", 
                      labels = c("OTHER", "NEW_CAR", "USED_CAR", "FURNITURE", 
                                 "RADIO/TV", "EDUCATION", "RETRAINING")) + 
  theme_bw()

```

We can see that the majority of the observations are fount in the purpose of getting a Radio or a TV, followed by a new car and then funriture, the one that is the less present is the education purpose. 

In terms of output variable, the highest differences can be found in the Radio/TV and new car, but this could be given by the fact that they are the purposes with the highest number of observations. 

#### Property 

Now we will create the property variable. 

We will start by looking at if the two variables that we want to use (namely, REAL_ESTATE and PROP_UNKN_NONE) are connected and hence it makes sense to put them together. 

In order to do so, as we previously mentioned, we will perform a chi-squared independence test. 

```{r chi-square test property}

chisq.test(data$REAL_ESTATE, data$PROP_UNKN_NONE)

```

We can see that the two variables are statistically significantly associated, as the p-value is really low, almost equal to 0, and hence is lower than the considered significance level of $$\alpha$$ = 5%.

We can conclude that it makes sense to merge the two variables into one factor variable, which will take value 1 if the person has a real estate, value 2 if the person is not known to have a property and value 0 otherwise. 

```{r property creation}

data %<>% 
  mutate(PROPERTY = as.factor(ifelse(REAL_ESTATE == 1, 1, 
                                     ifelse(PROP_UNKN_NONE == 1, 2, 0))))

```

Let's have a look also at this new variable, once again in terms of number of observations per level and if there is a difference of occurences given the output variables. 

```{r EDA PROPERTY}

data %>% 
ggplot(aes(PROPERTY)) + geom_bar(aes(fill = PROPERTY)) + scale_fill_discrete(name = "PROPERTY", labels = c("OTHER", "REAL_ESTATE", "PROP_UNKN_NONE")) + geom_label(stat = 'count', aes(label =..count..))  

data %>% 
  ggplot(aes(RESPONSE)) + geom_bar(aes(fill = PROPERTY), position = "dodge") + scale_fill_discrete(name = "PROPERTY", labels = c("OTHER", "REAL_ESTATE", "PROP_UNKN_NONE"))

```

We can clearly see that the majority of the observations does not have a clear value for the property, being equal to 0 (563 compared to the 282 of REAL_ESTATE and 154 of PROP_UNKN_NONE).

If we consider the response, we cannot really see a difference from the person having a real estate or not having a property and having a credit rejected, while if they have a real estate it is more probable that they will get the credit compared to those who have not.

#### Residence 

Now let's look at the third variable that we wish to know if it is needed to be created. 

This variable will be created using the RENT and OWN_RES variables to describe whether a person has a residence or not. 

Let's start once again by the chi-squared independence test. 

```{r chi-square residence}

chisq.test(data$RENT, data$OWN_RES)

```

Also here, we can conclude that the two variables are statistically significantly associated, as the p-value is really low, especially as it is lower than the significance level we have chosen.

Hence we will create the residence variable, which will take value 1 if the person is renting, value 2 if the person is owning their own residence and value 0 otherwise. 

```{r residence creation}

data %<>% 
  mutate(RESIDENCE = as.factor(ifelse(RENT == 1, 1, 
                                      ifelse(OWN_RES == 1, 2, 0))))

```


And let's explore the new variable a little bit, in terms of number of observations per level and if there is a difference in the possibility to get a credit given this variable. 

```{r RESIDENCE EDA}

data %>% 
  ggplot(aes(RESIDENCE)) + geom_bar(aes(fill = RESIDENCE)) + scale_fill_discrete(name = "RESIDENCE", labels = c("OTHER", "RENT", "OWN_RES"))+ geom_label(stat = 'count', aes(label =..count..)) 

data %>% 
  ggplot(aes(RESPONSE)) + geom_bar(aes(fill = RESIDENCE), position = "dodge") + scale_fill_discrete(name = "RESIDENCE", labels = c("OTHER", "RENT", "OWN_RES"))

```

Here, we can see that the majority of the people in the sample do own their own residence (712 observations, compared to the 108 of other and 179 who are renting). 

Comparing it to the response variable, we can see that owning the residence seems to have an impact on the possibility to get the credit, while renting seems not to have a major impact. 

## Select data 

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| Decide on the data to be used for analysis. Criteria include relevance to the data mining goals, quality and technical constraints such as limits on data volume or data types. Note that data selection covers selection of attributes (columns) as well as selection of records (rows) in a table. | List the data to be included/excluded and the reasons for these decisions.|

### Perform significance and correlation tests to decide what to include 

```{r correlation, echo=FALSE, fig.asp=1.2, message=FALSE, warning=FALSE}

cor(data[2:30], data$RESPONSE) 

```

We can see that, in general, the correlation between the output variable and the explanatory variable is not particularly high, having a maximum of 0.35 with CHECK_ACC and a minimum of -0.21 with DURATION. 

We could decide to select only the variables having a correlation higher than a certain absolute value, however, as the difference among the correlations is not really high, we prefer not to make a selection here, and rather leave this part for the modelling chapter and use a better process to make an eventual selection.

We will have a look at the linear model and the significance of the different variables to see which are considered to be the most important ones in this case, we are looking for consistency in the results.

```{r significance}

lm <- lm(RESPONSE ~ ., data = data[2:32])
summary(lm)$coeff[-1,4] < 0.05

```

Given the signifcance of the variable by running a simple linear regression model, we believe that the most important variables are CHK_ACCOUNT, DURATION, HISTORY, NEW_CAR, EDUCATION, AMOUNT, SAV_ACCOUNT, INSTALL_RATE, EMPLOYMENT, MALE_SINGLE, GUARANTOR, PROP_UNKN_NONE, OTHER_INSTALL, FOREIGN and  TELEPHONE, as they are the ones being significant at a level of at least 5%. This is in line with the correlation we have found before. 

We could choose to use only these variables, but we prefer to keep them and to perform a variable selection in terms of the different models that we will use in the next chapter. 

## Integrate data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| These are methods whereby information is combined from multiple tables or records to create new records or values. | Merging tables refers to joining together two or more tables that have different information about the same objects. </br> Merged data also covers aggregations. Aggregation refers to operations where new values are computed by summarizing together information from multiple records and/or tables.|

### Selecting variables we created and discard others 

Here we integrate the variables we created in the dataset and we discard the ones we used to create them, so that we avoid the problem of multicollinearity. 

We will need to drop also one of the variables we used to create the SEX_MALE variable, to avoid multicollinearity problems. The choice is on MALE_DIV.

We will also drop the identifier variable (OBS.) as it is not needed in the modelling part. 

```{r selection}

data_sel <- data %>% 
                dplyr::select(CHK_ACCT, DURATION, HISTORY, PURPOSE, 
                       AMOUNT, SAV_ACCT, EMPLOYMENT, INSTALL_RATE, 
                       SEX_MALE, MALE_SINGLE, MALE_MAR_or_WID, 
                       CO.APPLICANT, GUARANTOR, PRESENT_RESIDENT, 
                       PROPERTY, AGE, OTHER_INSTALL, RESIDENCE, 
                       NUM_CREDITS, JOB, TELEPHONE, RESPONSE)

```

## Format data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| Formatting transformations refer to primarily syntactic modifications made to the data that do not change its meaning, but might be required by the modeling tool. | Some tools have requirements on the order of the attributes, such as the first field being a unique identifier for each record or the last field being the outcome field the model is to predict. It might be important to change the order of the records in the dataset. Perhaps the modeling tool requires that the records be sorted according to the value of the outcome attribute.  Additionally, there are purely syntactic changes made to satisfy the requirements of the specific modeling tool.|

We will rename some variables for an easier use.

```{r renaming}

colnames(data_sel)[colnames(data_sel)=="MALE_MAR_or_WID"] <- "MALE_MAR_WID"
colnames(data_sel)[colnames(data_sel)=="CO.APPLICANT"] <- "CO_APPLICANT"

```

We will change the variables to factors for the dummies and the categorical variables, to have them corresponding to the description that has been given to us.

```{r}

data_sel %<>% 
  mutate(
    CHK_ACCT = as.factor(CHK_ACCT),
    HISTORY = as.factor(HISTORY),
    SAV_ACCT = as.factor(SAV_ACCT),
    EMPLOYMENT = as.factor(EMPLOYMENT),
    SEX_MALE = as.factor(SEX_MALE), 
    MALE_SINGLE = as.factor(MALE_SINGLE), 
    MALE_MAR_WID = as.factor(MALE_MAR_WID),
    CO_APPLICANT = as.factor(CO_APPLICANT),
    GUARANTOR = as.factor(GUARANTOR),
    PRESENT_RESIDENT = as.factor(PRESENT_RESIDENT), 
    OTHER_INSTALL = as.factor(OTHER_INSTALL),
    JOB = as.factor(JOB), 
    TELEPHONE = as.factor(TELEPHONE),
    RESPONSE = as.factor(RESPONSE)
  )


str(data_sel)
```

The selected dataset will hence have 999 observations of 22 different variables, 21 of which are the independent variables, 4 of which are continuous variable and the remaining are all categorical or dummy variables. The last variable is the output, which is also a dummy.

We are now ready to move on with the modelling part of our analysis. 