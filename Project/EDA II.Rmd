---
title: "EDA II"
output:
        bookdown::html_document2: default
        
---

# Exploratory data analysis

## Clean data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| Raise the data quality to the level required by the selected analysis techniques. This may involve selection of clean subsets of the data, the insertion of suitable defaults or more ambitious techniques such as the estimation of missing data by modeling.| Describe what decisions and actions were taken to address the data quality problems reported during the  verify data quality task of the data understanding phase. Transformations of the data for cleaning purposes and the possible impact on the analysis results should be considered. |


### Reconsider how to deal with observed type of noise 

We will consider how to correct the inconsistencies we have found in the previous chapter, which are on four different variables, namely:

- EDUCATION: there was an error in the registration of the information and the -1 must be replaced by 1.
- GUARANTOR: there was an error in the registration of the information and the 2 must be replaced by 1.
- PRESENT_RESIDENT: Again, there was an error in the registration of the information and the register was made in years instead of the category.
- AGE: Here it is clear that we have some outliers, we should limit the age to 75.

We have already decided how to correct them, hence we will move on to that direction. 

### Correct, remove or ignore noise 

We will start by correcting the noises of `EDUCATION`, `GUARANTOR` and `PRESENT_RESIDENT`, by simply replacing the value -1 and 2 with value 1 for the first two and by changing the numbers of the categories for the latter by dimishing each value by 1, this is going to give us the true value corresponding to the data description that you can find in the appendix. 

```{r noise correction}

#EDUCATION
data %<>% 
  mutate(EDUCATION = replace(EDUCATION, EDUCATION == -1, 1))

#EDUCATION
data %<>% 
  mutate(GUARANTOR = replace(GUARANTOR, GUARANTOR == 2, 1))

#PRESENT_RESIDENT 
data %<>% 
  mutate(PRESENT_RESIDENT = PRESENT_RESIDENT - 1)

```

### Decide how to deal with special values and their meaning 

This is specifically for the case of AGE. As previously said, we believe that the 125 age is an error, hence we will discard it by selecting only the observation with value lower then 76 (as 75 is the second highest value).

```{r age correction}

#AGE
data %<>% 
  filter(AGE < 76)

```

## Construct data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| This task includes constructive data preparation operations such as the production of derived attributes, entire new records or transformed values for existing attributes.| Derived attributes are new attributes that are constructed from one or more existing attributes in the same record. Examples: <br /> area = length * width. Describe the creation of completely new records. <br /> Example: create records for customers who made no purchase during the past year. There was no reason to have such records in the raw data, but for modeling purposes it might make sense to explicitly represent the fact that certain customers made zero purchases.|

### Check available constuction mechanisms 

As we already mentioned in the previous chapter, we will be able to create 4 different variables: 
1. A binary variable decribing the sex of the person (male vs. female)
2. A categorical variable for the purpose of the credit 
3. A categorical variable describing the real estate situation of the person (i.e. if someone owns a residence)
4. A categorical variable describing the property situation of the person (i.e. it they own their residence, are renting or something else)

#### Sex variable

We will start by the variable describing the sex of the considered person: this variable will be created thanks to the `MALE_DIV`, `MALE_SINGLE` and `MALE_MAR_WID` variables, and it will be a binary taking value 1 if the person is male, and value 0 if they are female. 

More specifically, if either one of the variables used to construct the new one has value 1, so will the `SEX_MALE` variable, otherwise it will have value 0. 

```{r male creation}

data %<>% 
  mutate(SEX_MALE = ifelse((MALE_DIV | MALE_SINGLE | MALE_MAR_or_WID) == 1, 1, 0)) %>% 
  mutate(SEX_MALE = as.factor(SEX_MALE))

```

We will now explore a bit the new variable we have created, by looking at the number of instances for each category and how it is affected in terms of response variable. 

```{r EDA SEX_MALE}

#Respesentation of SEX_MALE per value
data %>% 
  ggplot(aes(SEX_MALE)) + 
  geom_bar(aes(fill = factor(SEX_MALE))) + 
  theme(legend.position = "none")  + 
  geom_label(stat = 'count', aes(label =..count..)) 

#Representation of output variable in terms of SEX_MALE
data %>% 
  ggplot(aes(RESPONSE)) + 
  geom_bar(aes(fill = factor(SEX_MALE)), position = "dodge")+ 
  labs(color = "", fill = "SEX_MALE", x = "RESPONSE", y = "count") 

```

We can see from the first graph that we have more observation with a positive value for the SEX_MALE variable (690 vs. 309), meaning that there are more men than women in the dataset. 

Moreover, thanks to the second graph, we can see a difference on the positive value for the response having a male rather than a female, but this could also be due to the fact that the presence of male is higher with respect to female. 

### Collide variables 

We will now move on to the other variables aforementioned, so that instead of having multiple dummy variables, we have a factor variables with multiple levels. 

#### Purpose 

Let's start with the purpose of credit. 

This variable will take the following values:
1 = the purpose for the credit was a new car
2 = the purpose for the credit was a used car
3 = the purpose for the credit was funriture
4 = the purpose for the credit was a radio or a television 
5 = the purpose for the credit was to increase eductation 
6 = the purpose for the credit was a retraining 
0 = the purpose for the credit was something else 

It will be created by taking the respective value each time the dummy corresponding to one purpose takes value 1, if none of them has value 1, then the `PURPOSE`will take value 0.

```{r purpose creation}

data %<>% 
  mutate(PURPOSE = ifelse(NEW_CAR == 1, 1, 
                          ifelse(USED_CAR == 1, 2, 
                                 ifelse(FURNITURE == 1, 3, 
                                        ifelse(RADIO.TV == 1, 4, 
                                               ifelse(EDUCATION == 1, 5, 
                                                      ifelse(RETRAINING == 1, 6, 0))))))) %>% 
  mutate(PURPOSE = as.factor(PURPOSE))

```

Let's have a look at the new variable, in terms of number of observation per level and its link to the response variable. 

```{r EDA PURPOSE} 

data %>% 
  ggplot(aes(PURPOSE)) + 
  geom_bar(aes(reorder(PURPOSE, -table(PURPOSE)[PURPOSE]), fill = PURPOSE)) +
  scale_fill_discrete(name = "PURPOSE", 
                      labels = c("OTHER", "NEW_CAR", "USED_CAR", "FURNITURE", 
                                 "RADIO/TV", "EDUCATION", "RETRAINING")) + 
  geom_label(stat = 'count', aes(label =..count..)) 

data %>% 
  ggplot(aes(RESPONSE)) + 
  geom_bar(aes(fill = factor(PURPOSE)), position = "dodge") + 
  labs(x = "RESPONSE", y = "count") +  
  scale_fill_discrete(name = "PURPOSE", 
                      labels = c("OTHER", "NEW_CAR", "USED_CAR", "FURNITURE", 
                                 "RADIO/TV", "EDUCATION", "RETRAINING")) + 
  theme_bw()

```

In the first graph, we can see that the majority of the observations are found in the purpose of getting a Radio or a TV, followed by a new car and then furniture, while the one that is the less present is the education purpose. 

In terms of output variable, shown in the second graph, the highest differences can be found in the Radio/TV and new car, but this could be given by the fact that they are the purposes with the highest number of observations. 

#### Property 

Now we will create the property variable. 

We will start by looking at if the two variables that we want to use (namely, `REAL_ESTATE` and `PROP_UNKN_NONE`) are connected and hence it makes sense to put them together. 

In order to do so, as we previously mentioned, we will perform a chi-squared independence test. 

```{r chi-square test property}

chisq.test(data$REAL_ESTATE, data$PROP_UNKN_NONE)

```

We can see that the two variables are statistically significantly associated, as the p-value is really low, almost equal to 0, and hence is lower than the considered significance level of alpha = 5%.

We can conclude that it makes sense to merge the two variables into one factor variable, which will take value 1 if the person has a real estate, value 2 if the person is not known to have a property and value 0 otherwise. 

```{r property creation}

data %<>% 
  mutate(PROPERTY = as.factor(ifelse(REAL_ESTATE == 1, 1, 
                                     ifelse(PROP_UNKN_NONE == 1, 2, 0))))

```

Let's have a look also at this new variable, once again in terms of number of observations per level and if there is a difference of occurences given the output variables. 

```{r EDA PROPERTY}

data %>% 
ggplot(aes(PROPERTY)) + geom_bar(aes(fill = PROPERTY)) + scale_fill_discrete(name = "PROPERTY", labels = c("OTHER", "REAL_ESTATE", "PROP_UNKN_NONE")) + geom_label(stat = 'count', aes(label =..count..))  

data %>% 
  ggplot(aes(RESPONSE)) + geom_bar(aes(fill = PROPERTY), position = "dodge") + scale_fill_discrete(name = "PROPERTY", labels = c("OTHER", "REAL_ESTATE", "PROP_UNKN_NONE"))

```

We can clearly see in the first graph that the majority of the observations does not have a clear value for the property, being equal to 0 (563 compared to the 282 of `REAL_ESTATE` and 154 of `PROP_UNKN_NONE`).

If we consider the response, hence the second graph, we cannot really see a difference from the person having a real estate or not having a property and having a credit rejected, while if they have a real estate it is more probable that they will get the credit compared to those who have not.

#### Residence 

Now let's look at the third variable that we wish to know if it is needed to be created. 

This variable will be created using the `RENT` and `OWN_RES` variables to describe whether a person has a residence or not. 

Let's start once again by the chi-squared independence test. 

```{r chi-square residence}

chisq.test(data$RENT, data$OWN_RES)

```

Also here, we can conclude that the two variables are statistically significantly associated, as the p-value is really low, especially as it is lower than the significance level we have chosen of alpha being equal to 5%.

Hence, we will create the residence variable, which will take value 1 if the person is renting, value 2 if the person is owning their own residence and value 0 otherwise. 

```{r residence creation}

data %<>% 
  mutate(RESIDENCE = as.factor(ifelse(RENT == 1, 1, 
                                      ifelse(OWN_RES == 1, 2, 0))))

```

And let's explore the new variable a little bit, in terms of number of observations per level and if there is a difference in the possibility to get a credit given this variable. 

```{r RESIDENCE EDA}

data %>% 
  ggplot(aes(RESIDENCE)) + geom_bar(aes(fill = RESIDENCE)) + scale_fill_discrete(name = "RESIDENCE", labels = c("OTHER", "RENT", "OWN_RES"))+ geom_label(stat = 'count', aes(label =..count..)) 

data %>% 
  ggplot(aes(RESPONSE)) + geom_bar(aes(fill = RESIDENCE), position = "dodge") + scale_fill_discrete(name = "RESIDENCE", labels = c("OTHER", "RENT", "OWN_RES"))

```

In the first graph, we can see that the majority of the people in the sample do own their own residence (712 observations, compared to the 108 of other and 179 who are renting). 

Looking at the second graph, comparing it to the response variable, we can see that owning the residence seems to have an impact on the possibility to get the credit, while renting seems not to have a major impact. 

## Integrate data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| These are methods whereby information is combined from multiple tables or records to create new records or values. | Merging tables refers to joining together two or more tables that have different information about the same objects. </br> Merged data also covers aggregations. Aggregation refers to operations where new values are computed by summarizing together information from multiple records and/or tables.|

### Selecting variables we created and discard others 

Here we integrate the variables we created in the dataset and we discard the ones we used to create them, so that we avoid the problem of multicollinearity. 

We will need to drop also one of the variables we used to create the `SEX_MALE` variable, to avoid multicollinearity problems. The choice is on `MALE_DIV`.

We will also drop the identifier variable (`OBS.`) as it is not needed in the modelling part. 

```{r selection}

data_sel <- data %>%
                dplyr::select(CHK_ACCT, DURATION, HISTORY, PURPOSE,
                       AMOUNT, SAV_ACCT, EMPLOYMENT, INSTALL_RATE,
                       SEX_MALE, MALE_SINGLE, MALE_MAR_or_WID,
                       CO.APPLICANT, GUARANTOR, PRESENT_RESIDENT,
                       PROPERTY, AGE, OTHER_INSTALL, RESIDENCE,
                       NUM_CREDITS, JOB, TELEPHONE, RESPONSE) 

```

## Select data 

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| Decide on the data to be used for analysis. Criteria include relevance to the data mining goals, quality and technical constraints such as limits on data volume or data types. Note that data selection covers selection of attributes (columns) as well as selection of records (rows) in a table. | List the data to be included/excluded and the reasons for these decisions.|

To further select the data we will use the correlation and we will run a simple linear model to have a look at which are the most important variables to be selected.

We start with the correlation and we use the basic dataset, because we cannot run a correlation on factor variables. 

```{r correlation, echo=FALSE, fig.asp=1.2, message=FALSE, warning=FALSE}

cor(data[2:30], data$RESPONSE) %>% as.data.frame() %>% dplyr::arrange(abs(V1))

```

We can see that, in general, the correlation between the output variable and the explanatory variable is not particularly high, having a maximum of 0.35 with `CHCK_ACC` and a minimum of -0.00306 with `PRESENTE_RESIDENT`, in absolute terms. 

We could decide to select only the variables having a correlation higher than a certain absolute value, however, as the difference among the correlations is not really high, we prefer not to make a selection here, and rather leave this decision to the modelling of a simple linear regression and a choice made on the AIC.

> The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data.
source: https://www.scribbr.com/statistics/akaike-information-criterion/

The step function follows the idea that the variable that increases the AIC of the model the most will be discarder, up to the point in which it is not possible to decrease the AIC anymore. 

### Perform significance and correlation tests to decide what to include 

```{r linear model to select data}

set.seed(2143)
lm.sel <- glm(RESPONSE ~., data = data_sel)
lm.sel <- step(lm.sel, trace = 0)
summary(lm.sel) 
data_sel <- lm.sel$model

```

Thanks to the AIC, we select the following variables: `CHK_ACCT`, `DURATION`, `HISTORY`, `PURPOSE`, `AMOUNT`, `SAV_ACCT`, `EMPLOYMENT`, `INSTALL_RATE`, `MALE_SINGLE`, `GUARANTOR`, `PROPERTY`, `OTHER_INSTALL`, `RESIDENCE`, `NUM_CREDITS` and `TELEPHONE`, as they are the most significant. It is interesting to note that there are some levels of purpose that seem to be less relevant, more specifically the only one that are statistically significant are the first and the fifth.
Moreover, we can see that there is coherence with the variables that had the highest correlations that we calculated before, hence we will use this method to make our final selection on the data. 

## Format data

| Task                                       | Output                                      | 
|:-------------------------------------------|:--------------------------------------------|
| Formatting transformations refer to primarily syntactic modifications made to the data that do not change its meaning, but might be required by the modeling tool. | Some tools have requirements on the order of the attributes, such as the first field being a unique identifier for each record or the last field being the outcome field the model is to predict. It might be important to change the order of the records in the dataset. Perhaps the modeling tool requires that the records be sorted according to the value of the outcome attribute.  Additionally, there are purely syntactic changes made to satisfy the requirements of the specific modeling tool.|

We will change the variables to factors for the dummies and the categorical variables, to have them corresponding to the description that has been given to us.

```{r}

data_sel %<>% 
  mutate(
    CHK_ACCT = as.factor(CHK_ACCT),
    HISTORY = as.factor(HISTORY),
    SAV_ACCT = as.factor(SAV_ACCT),
    EMPLOYMENT = as.factor(EMPLOYMENT),
    MALE_SINGLE = as.factor(MALE_SINGLE), 
    GUARANTOR = as.factor(GUARANTOR),
    OTHER_INSTALL = as.factor(OTHER_INSTALL),
    TELEPHONE = as.factor(TELEPHONE),
    RESPONSE = as.factor(RESPONSE)
  )


str(data_sel)

```

The selected dataset will hence have 999 observations of 16 different variables, 15 of which are the independent variables, 4 of which are continuous variable (i.e.: `DURATION`,`AMOUNT`,`INSTALL_RATE` and `NUN_CREDITS`) and the remaining are all categorical or dummy variables. The first variable is the output (i.e. `RESPONSE`), which is also a dummy.

We are now ready to move on with the modelling part of our analysis. 