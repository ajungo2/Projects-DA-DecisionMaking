summary(mod_qda_fitbalance)
qda.pred.b <- predict(mod_qda_fitbalance, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(qda.pred.b), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
#########
sens.b<- caret::sensitivity(table(as.factor(qda.pred.b), as.factor(TestData$RESPONSE)))
sp.b<- caret::specificity(table(as.factor(qda.pred.b), as.factor(TestData$RESPONSE)))
acc.b<- 0.679
qda_balance<- c(sens.b , sp.b, acc.b)
#############remove temporary element
rm(cm, sens.b, sp.b, acc.b)
#Same division
set.seed(1234)
#########################model######################################vvvv
train_params <- trainControl(method = "repeatedcv", number = 10, repeats=5) #K-Fold Cross Validation
library(earth)
install.packages("earth")
#Same division
set.seed(1234)
#########################model######################################vvvv
train_params <- trainControl(method = "repeatedcv", number = 10, repeats=5) #K-Fold Cross Validation
library(earth)
mod_fda_fit <- caret::train(RESPONSE ~ ., TrainData, method="fda",
trControl= train_params)
################check outputs################################vv
summary(mod_fda_fit)
fda.pred <- predict(mod_fda_fit, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(fda.pred), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
#############
sens<- caret::sensitivity(table(as.factor(fda.pred), as.factor(TestData$RESPONSE)))
sp<- caret::specificity(table(as.factor(fda.pred), as.factor(TestData$RESPONSE)))
acc<- 0.759
fda<- c(sens , sp, acc)
#############remove temporary element
rm(cm, sens, sp, acc)
mod_fda_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="fda",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
mod_fda_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="fda",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
summary(mod_fda_fitbalance)
fda.pred.b <- predict(mod_fda_fitbalance, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(fda.pred.b), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
#####################
sens.b<- caret::sensitivity(table(as.factor(fda.pred.b), as.factor(TestData$RESPONSE)))
sp.b<- caret::specificity(table(as.factor(fda.pred.b), as.factor(TestData$RESPONSE)))
acc.b<- 0.598
fda_balance<- c(sens.b , sp.b, acc.b)
#############remove temporary element
rm(cm, sens.b, sp.b, acc.b)
#Same division
set.seed(1234)
#########################model######################################vvvv
train_params <- trainControl(method = "repeatedcv", number = 10, repeats=5) #K-Fold Cross Validation
mod_mda_fit <- caret::train(RESPONSE ~ ., TrainData, method="mda",
family="binomial",trControl= train_params)
################check outputs################################vv
summary(mod_mda_fit)
mda.pred <- predict(mod_mda_fit, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(mda.pred), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
#############remove temporary element
sens<- caret::sensitivity(table(as.factor(mda.pred), as.factor(TestData$RESPONSE)))
sp<- caret::specificity(table(as.factor(mda.pred), as.factor(TestData$RESPONSE)))
acc<- 0.739
mda<- c(sens , sp, acc)
#############remove temporary element
rm(cm, sens, sp, acc)
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down", classProbs = TRUE,
summaryFunction = twoClassSummary)
mod_mda_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="mda",
family="binomial",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
mod_mda_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="mda",
family="binomial",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
train_params <- trainControl(method = "repeatedcv", number = 10, repeats=5) #K-Fold Cross Validation
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down" )
mod_mda_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="mda",
family="binomial",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
summary(mod_mda_fitbalance)
mda.pred.b <- predict(mod_mda_fitbalance, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(mda.pred.b), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
#########
sens.b<- caret::sensitivity(table(as.factor(mda.pred.b), as.factor(TestData$RESPONSE)))
sp.b<- caret::specificity(table(as.factor(mda.pred.b), as.factor(TestData$RESPONSE)))
acc.b<- 0.675
mda_balance<- c(sens.b , sp.b, acc.b)
#############remove temporary element
rm(cm, sens.b, sp.b, acc.b)
#Same division
set.seed(1234)
#########################model######################################vvvv
train_params <- trainControl(method = "repeatedcv", number = 10, repeats=5) #K-Fold Cross Validation
mod_rf_fit <- caret::train(RESPONSE ~ ., TrainData, method="rf",
trControl= train_params)
################check outputs################################vv
summary(mod_rf_fit)
rf.pred <- predict(mod_rf_fit, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(rf.pred), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
############
sens<- caret::sensitivity(table(as.factor(rf.pred), as.factor(TestData$RESPONSE)))
sp<- caret::specificity(table(as.factor(rf.pred), as.factor(TestData$RESPONSE)))
acc<- 0.747
rf<- c(sens , sp, acc)
#############remove temporary element
rm(cm, sens, sp, acc)
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down",
summaryFunction = twoClassSummary)
mod_rf_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="rf",
family="binomial",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down"),
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down")
mod_rf_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="rf",
family="binomial",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
summary(mod_rf_fitbalance)
rf.pred.b <- predict(mod_rf_fitbalance, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
######################
sens.b<- caret::sensitivity(table(as.factor(rf.pred.b), as.factor(TestData$RESPONSE)))
sp.b<- caret::specificity(table(as.factor(rf.pred.b), as.factor(TestData$RESPONSE)))
acc.b<- 0.651
rf_balance<- c(sens.b , sp.b, acc.b)
#############remove temporary element
rm(cm, sens.b, sp.b, acc.b)
#Same division
set.seed(1234)
#########################model######################################vvvv
train_params <- trainControl(method = "repeatedcv", number = 10, repeats=5) #K-Fold Cross Validation
mod_nn_fit <- caret::train(RESPONSE ~ ., TrainData, method="nnet",
trControl= train_params)
################check outputs################################
#summary(mod_nn_fit) #this is very long
library(nnet)
NeuralNetTools::plotnet(mod_nn_fit$finalModel, y_names = "yes/no")
install.packages("NeuralNetTools")
library(nnet)
NeuralNetTools::plotnet(mod_nn_fit$finalModel, y_names = "yes/no")
title("Graphical Representation of our Neural Network")
nn.pred <- predict(mod_nn_fit, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
nn.pred <- predict(mod_nn_fit, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(nn.pred), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
#############
sens<- caret::sensitivity(table(as.factor(nn.pred), as.factor(TestData$RESPONSE)))
sp<- caret::specificity(table(as.factor(nn.pred), as.factor(TestData$RESPONSE)))
acc<- 0.763
nn<- c(sens , sp, acc)
#############remove temporary element
rm(cm, sens, sp, acc)
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down")
mod_nn_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="nnet",
family="binomial",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
summary(mod_nn_fitbalance)
nn.pred.b <- predict(mod_nn_fitbalance, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
cm <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))
draw_confusion_matrix(cm)
sens.b<- caret::sensitivity(table(as.factor(nn.pred.b), as.factor(TestData$RESPONSE)))
sp.b<- caret::specificity(table(as.factor(nn.pred.b), as.factor(TestData$RESPONSE)))
acc.b<- 0.679
nn_balance<- c(sens.b , sp.b, acc.b)
rm(cm, sens.b, sp.b, acc.b)
columna %>%
as.factor() %>%
as.numeric %>%
{ . - 1 } })
data_xgboost <- map_df(data_scale, function(columna) {
columna %>%
as.factor() %>%
as.numeric %>%
{ . - 1 } })
test_xgboost <- sample_frac(data_xgboost, size = 0.249)
train_xgboost <- setdiff(data_xgboost, test_xgboost)
train_xgb_matrix <-   train_xgboost %>%
dplyr::select(- RESPONSE) %>%
as.matrix() %>%
xgboost::xgb.DMatrix(data = ., label = train_xgboost$RESPONSE)
test_xgb_matrix <-  test_xgboost %>%
dplyr::select(- RESPONSE) %>%
as.matrix() %>%
xgboost::xgb.DMatrix(data = ., label = test_xgboost$RESPONSE)
set.seed(1234)
train_params <- trainControl(method = "repeatedcv",
number = 10, # with n folds
repeats=5) #K-Fold Cross Validation
mod_xgb_fit <- caret::train(RESPONSE ~ ., TrainData,
method="xgbTree",
trControl= train_params)
mod_xgb_fit <- caret::train(RESPONSE ~ ., TrainData,
method="xgbTree",
trControl= train_params)
summary(mod_xgb_fit)
mod_xgb_fit$bestTune
#############confusion matrix
cm <- confusionMatrix(as.factor(xgb.pred), as.factor(TestData$RESPONSE))
xgb.pred <- predict(mod_xgb_fit, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(xgb.pred), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
######################
sens<- caret::sensitivity(table(as.factor(xgb.pred), as.factor(TestData$RESPONSE)))
sp<- caret::specificity(table(as.factor(xgb.pred), as.factor(TestData$RESPONSE)))
acc<- 0.743
xgb<- c(sens , sp, acc)
#############remove temporary element
rm(cm, sens, sp, acc)
train_params <- caret::trainControl(method = "repeatedcv", number = 10,
repeats=5, sampling = "down")
mod_xgb_fitbalance <- caret::train(RESPONSE ~ ., TrainData, method="xgbTree",
metric = "Sens", #optimize sensitivity
maximize = TRUE,
trControl= train_params)
summary(mod_xgb_fitbalance)
xgb.pred.b <- predict(mod_xgb_fitbalance, newdata = TestData)  #predict give me the probability i am looking for the the binomial answer
#############confusion matrix
cm <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))
############draw of confusion matrix
draw_confusion_matrix(cm)
######################
sens.b<- caret::sensitivity(table(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE)))
sp.b<- caret::specificity(table(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE)))
acc.b<- 0.723
xgb_balance<- c(sens.b , sp.b, acc.b)
#############remove temporary element
rm(cm, sens.b, sp.b, acc.b)
Details<- c("Sensitivity", "Specificity", "Accuracy")
summary_table<- data.frame(Details, logistic, logistic_balance,
decision_tree, decision_tree_balance,
lda, lda_balance,
qda, qda_balance,
fda, fda_balance,
mda, mda_balance,
rf, rf_balance,
nn, nn_balance,
xgb, xgb_balance)
summary_table<-data.frame(t(summary_table[-1]))
names(summary_table) <- c("Sensitivity", "Specificity", "Accuracy")
summary_table
sens.b
sens.b<- caret::sensitivity(table(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE)))
sens.b
caret::sensitivity(table(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE)))
confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))
cm <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))
cm$table
cm$table[2,1]
cm$table
cm <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
cm
confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.xgb <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.rf <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.nn <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.xgb <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
cbind(fp.rp, fp.nn, fp.xgb)
fp.rf <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.nn <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.xgb <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
cbind(fp.rf, fp.nn, fp.xgb)
data.frame(fp.rf, fp.nn, fp.xgb)
fp.rf <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.nn <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.xgb <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
data.frame(fp.rf, fp.nn, fp.xgb)
names <- c("Model", "False_Positive")
data.frame(names, fp.rf, fp.nn, fp.xgb)
fp.rf <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.nn <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
fp.xgb <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
data.frame(fp.rf, fp.nn, fp.xgb)
names(data.frame(fp.rf, fp.nn, fp.xgb)) = c("RF", "NN", "XGB")
RF <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
NN <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
XGB <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
data.frame(RF, NN, XGB)
summary_table<- data.frame(Details, logistic, logistic_balance,
decision_tree, decision_tree_balance,
lda, lda_balance,
qda, qda_balance,
fda, fda_balance,
mda, mda_balance,
rf, rf_balance,
nn, nn_balance,
xgb, xgb_balance)
summary_table
summary_table<-data.frame(t(summary_table[-1]))
summary_table
FP <- data.frame(RF, NN, XGB)
FP <- data.frame(t(RF, NN, XGB))
RF <- confusionMatrix(as.factor(rf.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
NN <- confusionMatrix(as.factor(nn.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
XGB <- confusionMatrix(as.factor(xgb.pred.b), as.factor(TestData$RESPONSE))$table[2,1]
FP <- data.frame(t(RF, NN, XGB))
FP <- data.frame(t(data.frame(RF, NN, XGB)))
FP
names(FP) <- c("Model", "False Positive")
F
FP
names(FP) <- c("False Positive")
FP
FP
NN
FP %>% dplyr::mutate(Perc = "False Positive"/nrow(TestData))
"False Positive"
FP %>% dplyr::mutate(Perc = FP[,1]/nrow(TestData))
FP %>% dplyr::mutate(Perc = perc(FP[,1]/nrow(TestData)))
FP %>% dplyr::mutate(Perc = label_percent(FP[,1]/nrow(TestData)))
FP %>% dplyr::mutate(Perc = (FP[,1]/nrow(TestData))
FP %>% dplyr::mutate(Perc = (FP[,1]/nrow(TestData)))
FP %>% dplyr::mutate(Perc = (FP[,1]/nrow(TestData)))
FP %>% dplyr::mutate(Model = c("RF", "NN", "XGB", Perc = (FP[,1]/nrow(TestData)))
FP %>% dplyr::mutate(Model = c("RF", "NN", "XGB"), Perc = (FP[,1]/nrow(TestData)))
FP %>% dplyr::mutate(Model = c("RF", "NN", "XGB"),
Perc = (FP[,1]/nrow(TestData)))
rf.pred.b
ifelse(rf.pred.b = TestData$RESPONSE, 0, 1)
rf.pred.b
TestData$RESPONSE
ifelse(rf.pred.b = TestData$RESPONSE, 0, 1)
ifelse(rf.pred.b == TestData$RESPONSE, 0, 1)
sum(ifelse(rf.pred.b == TestData$RESPONSE, 0, 1))
sum(ifelse((rf.pred.b == 1 & TestData$RESPONSE == 0), 0, 1))
sum(ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 0, 1))
(ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 0, 1))
(ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
sum(ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
(ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
fp.rf <- (ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
fp.rf * TestData$AMOUNT
fp.rf * unscale(TestData$AMOUNT)
install.packages("DMwR")
fp.rf * DMwR::unscale(TestData$AMOUNT)
TestData$AMOUNT
unscale(TestData$AMOUNT)
library
library(DMwR)
unscale(TestData$AMOUNT)
fp.rf * unscale(TestData$AMOUNT, norm.data = data_scale)
fp.rf * unscale(TestData$AMOUNT, norm.data = data)
fp.rf * unscale(TestData$AMOUNT, norm.data = data$AMOUNT)
unscale(TestData$AMOUNT, norm.data = data$AMOUNT)
unscale(TestData$AMOUNT, norm.data = data)
unscale(TestData$AMOUNT, norm.data = data_scale)
unscale(TestData$AMOUNT, norm.data = data_scale, col.ids = AMOUNT)
unscale(TestData$AMOUNT, norm.data = data_scale, col.ids = data_scale$AMOUNT)
unscale(TestData$AMOUNT, norm.data = TestData, col.ids = TestData$AMOUNT)
unscale(TrainData, data_scale)
unscale(TestData$AMOUNT)
unscale(TestData$AMOUNT, norm.data = data_scale$AMOUNT)
amount <- TestData$AMOUNT * attr(TestData$AMOUNT, 'scaled:scale') + attr(TestData$AMOUNT, 'scaled:center')
amount
attr(TestData$AMOUNT, 'scaled:scale')
data_sel[-val_index,]
testunscale <- data_sel[-val_index,]
View(testunscale)
View(testunscale)
View(TestData)
View(TestData)
amount <- data_sel[-val_index,]$AMOUNT
amount
fp.rf * amount
sum(fp.rf * amount)
fp.nn <- (ifelse(nn.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
sum(fp.nn * amount)
fp.xgb <- (ifelse(xgb.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
sum(fp.xgb * amount)
amount <- data_sel[-val_index,]$AMOUNT
fp.rf <- (ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
sum(fp.rf * amount)
fp.nn <- (ifelse(nn.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
sum(fp.nn * amount)
fp.xgb <- (ifelse(xgb.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
sum(fp.xgb * amount)
amount <- data_sel[-val_index,]$AMOUNT
fp.rf <- (ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
losses.rf <- sum(fp.rf * amount)
fp.nn <- (ifelse(nn.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
losses.nn <- sum(fp.nn * amount)
fp.xgb <- (ifelse(xgb.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
losses.xgb <- sum(fp.xgb * amount)
Losses <- data.frame(losses.rf, losses.nn, losses.xgb)
Losses
Losses <- data.frame(t(Losses))
Losses
names(Losses) <- "Losses"
Losses
losses.rf
losses.nn
names(data_sel)
Losses %>% dplyr::mutate(Model = c("RF", "NN", "XGB")) %>% dplyr::select(Model, Losses)
Losses %<>% dplyr::mutate(Model = c("RF", "NN", "XGB")) %>% dplyr::select(Model, Losses)
Loses
Losses
Losses %>% dplyr::mutate(Perc = Losses / sum(amount))
pos <- ifelse(amount == 1, 1, 0)
pos
amount
data_sel[-val_index,]
sel <- data_sel[-val_index,]
sel %>% dplyr::filter(RESPONSE == 1)
pos <- sel %>% dplyr::filter(RESPONSE == 1) %>% select(AMOUNT)
pos <- sel %>% dplyr::filter(RESPONSE == 1) %>% dplyr::select(AMOUNT)
pos
Losses %>% dplyr::mutate(Perc = Losses / sum(pos))
names(data_sel)
names(data_sel[-1,])
names(data_sel[,-1])
names(data_sel[,-1])
FP
Losses[2,3]
Losses[3,2]
Losses[2,3]
sel <- data_sel[-val_index,] #getting the observations unscaled
pos <- sel %>% dplyr::filter(RESPONSE == 1) %>% dplyr::select(AMOUNT) #selecting only the amount of the credits that are granted
Losses %>% dplyr::mutate(Perc = Losses / sum(pos))
Losses[2,3]
Losses[2,2]
Losses[3,2]
Losses[2,3]
sel <- data_sel[-val_index,] #getting the observations unscaled
pos <- sel %>% dplyr::filter(RESPONSE == 1) %>% dplyr::select(AMOUNT) #selecting only the amount of the credits that are granted
Losses %<>% dplyr::mutate(Perc = Losses / sum(pos))
Losses
Losses[2,3]
Losses[1,3]
cbind(FP, Losses)
cbind(FP, Losses[,-1])
Losses %<>% dplyr::mutate(Losses Perc = Losses / sum(pos))
Losses %<>% dplyr::mutate(Losses_Perc = Losses / sum(pos))
Losses
amount <- data_sel[-val_index,]$AMOUNT
fp.rf <- (ifelse(rf.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
losses.rf <- sum(fp.rf * amount)
fp.nn <- (ifelse(nn.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
losses.nn <- sum(fp.nn * amount)
fp.xgb <- (ifelse(xgb.pred.b == 1 & TestData$RESPONSE == 0, 1, 0))
losses.xgb <- sum(fp.xgb * amount)
Losses <- data.frame(losses.rf, losses.nn, losses.xgb)
Losses <- data.frame(t(Losses))
names(Losses) <- "Losses"
Losses %<>% dplyr::mutate(Model = c("RF", "NN", "XGB")) %>% dplyr::select(Model, Losses)
Losses
sel <- data_sel[-val_index,] #getting the observations unscaled
pos <- sel %>% dplyr::filter(RESPONSE == 1) %>% dplyr::select(AMOUNT) #selecting only the amount of the credits that are granted
Losses %<>% dplyr::mutate(Losses_Perc = Losses / sum(pos))
Losses
cbind(FP, Losses[,-1])
FP %<>% dplyr::mutate(Model = c("RF", "NN", "XGB"),
FP_Perc = (FP[,1]/nrow(TestData)))
FP
cbind(FP, Losses[,-1])
FP %<>% dplyr::mutate(Model = c("RF", "NN", "XGB"),
FP_Perc = (FP[,1]/nrow(TestData))) %>% dplyr::select("Model", everything())
FP
cbind(FP, Losses[,-1])
names(data_sel[,-1])
names(data_sel[,-1])
rf[3]
rf_balance[3]
NeuralNetTools::plotnet(mod_nn_fit$finalModel, y_names = "yes/no")
NeuralNetTools::plotnet(nn.fit$finalModel, y_names = "yes/no")
